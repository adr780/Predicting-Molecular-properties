{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model\n",
    "\n",
    "The objective of this model is to generate predictions using a model for each coupling type. The type of model used is a random forest with 50 trees and with a slight hyperparameter tuning. The score achieved with this model is -0.848 on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from magnetic_interactions import data_utils as du\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Feature Generation\n",
    "\n",
    "The following cell joins in a single dataframe all the features generated for the challenge. The features are loaded from previously created csv files for time purposes.\n",
    "\n",
    "The result of running the cell are dictionaries with a dataframe for each one of the eight coupling types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 106.62 Mb (50.0% reduction)\n",
      "Mem. usage decreased to 51.74 Mb (52.1% reduction)\n",
      "Mem. usage decreased to 279.87 Mb (53.3% reduction)\n",
      "Mem. usage decreased to 342.06 Mb (33.0% reduction)\n",
      "Mem. usage decreased to 350.95 Mb (15.1% reduction)\n",
      "Mem. usage decreased to 364.27 Mb (13.7% reduction)\n",
      "Mem. usage decreased to 852.93 Mb (63.2% reduction)\n",
      "Mem. usage decreased to 128.54 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 68.50 Mb (0.0% reduction)\n",
      "Mem. usage decreased to  7.86 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 21.61 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 206.69 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 107.02 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 273.68 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 30.15 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 52.57 Mb (45.0% reduction)\n",
      "Mem. usage decreased to 51.74 Mb (52.1% reduction)\n",
      "Mem. usage decreased to 145.76 Mb (54.1% reduction)\n",
      "Mem. usage decreased to 179.21 Mb (33.6% reduction)\n",
      "Mem. usage decreased to 183.99 Mb (15.4% reduction)\n",
      "Mem. usage decreased to 191.16 Mb (14.0% reduction)\n",
      "Mem. usage decreased to 454.00 Mb (63.5% reduction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlosmiguelpatino/Lacuna/projects/MagneticInteractionsChallenge/magnetic_interactions/data_utils.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.int32)\n",
      "/home/carlosmiguelpatino/Lacuna/projects/MagneticInteractionsChallenge/magnetic_interactions/data_utils.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 111.10 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 68.97 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 57.52 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 147.13 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 36.81 Mb (0.0% reduction)\n",
      "Mem. usage decreased to  4.38 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 16.42 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 11.67 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_data_path = './data/champs-scalar-coupling/train.csv'\n",
    "test_data_path = './data/champs-scalar-coupling/test.csv'\n",
    "\n",
    "structures_data_path = './data/champs-scalar-coupling/structures.csv'\n",
    "\n",
    "angles_torsions_train_path = './data/champs-scalar-coupling/angles_torsions_train.csv'\n",
    "angles_torsions_test_path = './data/champs-scalar-coupling/angles_torsions_test.csv'\n",
    "bonds_train_path = './data/champs-scalar-coupling/bonds_train.csv'\n",
    "bonds_test_path = './data/champs-scalar-coupling/bonds_test.csv'\n",
    "\n",
    "distances_train_path = './data/champs-scalar-coupling/distance_features_train.csv'\n",
    "distances_test_path = './data/champs-scalar-coupling/distance_features_test.csv'\n",
    "\n",
    "spins_train_path = './data/champs-scalar-coupling/spin_feature_train.csv'\n",
    "spins_test_path = './data/champs-scalar-coupling/spin_feature_test.csv'\n",
    "\n",
    "hyb_train_path = './data/champs-scalar-coupling/hyb_train.csv'\n",
    "hyb_test_path = './data/champs-scalar-coupling/hyb_test.csv'\n",
    "\n",
    "features_camilo_train_path = './data/champs-scalar-coupling/features_camilo_train.csv'\n",
    "features_camilo_test_path = './data/champs-scalar-coupling/features_camilo_test.csv'\n",
    "\n",
    "train_dfs_dict, targets_dict = du.data_pipeline(train_data_path, structures_data_path, \n",
    "                                                angles_torsions_train_path, bonds_train_path, \n",
    "                                                distances_train_path, spins_train_path, hyb_train_path,\n",
    "                                                features_camilo_train_path,\n",
    "                                                train_data=True)\n",
    "test_dfs_dict, _ = du.data_pipeline(test_data_path, structures_data_path, angles_torsions_test_path, \n",
    "                                    bonds_test_path, distances_test_path, spins_test_path, hyb_test_path,\n",
    "                                    features_camilo_test_path,\n",
    "                                    train_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Select which features are going to be used for training the model for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_coupling_type = {\n",
    "    \n",
    "    '1JHC': ['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1', 'n_atoms', 'n_C', 'n_F',\n",
    "            'n_H', 'n_N', 'n_O', 'type_1__C', 'type_1__H', 'type_1__N',\n",
    "            'n_bonds_mol', 'n_bonds_0', 'n_bonds_1', \n",
    "            'max_distance_mol' , 'mean_distance_mol', 'dist','1/r2',\n",
    "            'spin', 'n_hyb_3', 'hyb_coupled_atom', '1/hyb', \n",
    "            'volume', 'max diag', 'median diag', 'min diag',\n",
    "       'distance_atomic_weight_0', 'distance_en_allen_0',\n",
    "       'distance_atomic_weight_1', 'distance_en_allen_1', 'C_0d_0', 'N_0d_0',\n",
    "       'O_0d_0', 'C_1d_0', 'H_1d_0', 'N_1d_0', 'O_1d_0', 'C_2d_0', 'F_2d_0',\n",
    "       'H_2d_0', 'N_2d_0', 'O_2d_0', 'C_3d_0', 'F_3d_0', 'H_3d_0', 'N_3d_0',\n",
    "       'O_3d_0', 'C_4d_0', 'F_4d_0', 'H_4d_0', 'N_4d_0', 'O_4d_0', 'C_0d_1',\n",
    "       'F_0d_1', 'H_0d_1', 'N_0d_1', 'O_0d_1', 'C_1d_1', 'F_1d_1', 'H_1d_1',\n",
    "       'N_1d_1', 'O_1d_1', 'C_2d_1', 'F_2d_1', 'H_2d_1', 'N_2d_1', 'O_2d_1',\n",
    "       'C_3d_1', 'F_3d_1', 'H_3d_1', 'N_3d_1', 'O_3d_1', 'C_4d_1', 'F_4d_1',\n",
    "       'H_4d_1', 'N_4d_1', 'O_4d_1'],\n",
    "    '2JHH': ['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1', 'n_atoms', 'n_C', 'n_F',\n",
    "            'n_H', 'n_N', 'n_O', 'type_1__C', 'type_1__H', 'type_1__N', 'angles',\n",
    "            'n_bonds_mol', 'n_bonds_0', 'n_bonds_1',\n",
    "            'max_distance_mol' , 'mean_distance_mol', 'dist','1/r2',\n",
    "            'spin', 'n_hyb_3', 'hyb_coupled_atom', '1/hyb',\n",
    "            'volume', 'max diag', 'median diag', 'min diag',\n",
    "       'distance_atomic_weight_0', 'distance_en_allen_0',\n",
    "       'distance_atomic_weight_1', 'distance_en_allen_1', 'C_0d_0', 'N_0d_0',\n",
    "       'O_0d_0', 'C_1d_0', 'H_1d_0', 'N_1d_0', 'O_1d_0', 'C_2d_0', 'F_2d_0',\n",
    "       'H_2d_0', 'N_2d_0', 'O_2d_0', 'C_3d_0', 'F_3d_0', 'H_3d_0', 'N_3d_0',\n",
    "       'O_3d_0', 'C_4d_0', 'F_4d_0', 'H_4d_0', 'N_4d_0', 'O_4d_0', 'C_0d_1',\n",
    "       'F_0d_1', 'H_0d_1', 'N_0d_1', 'O_0d_1', 'C_1d_1', 'F_1d_1', 'H_1d_1',\n",
    "       'N_1d_1', 'O_1d_1', 'C_2d_1', 'F_2d_1', 'H_2d_1', 'N_2d_1', 'O_2d_1',\n",
    "       'C_3d_1', 'F_3d_1', 'H_3d_1', 'N_3d_1', 'O_3d_1', 'C_4d_1', 'F_4d_1',\n",
    "       'H_4d_1', 'N_4d_1', 'O_4d_1'],\n",
    "    '1JHN': ['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1', 'n_atoms', 'n_C', 'n_F',\n",
    "            'n_H', 'n_N', 'n_O', 'type_1__C', 'type_1__H', 'type_1__N',\n",
    "            'n_bonds_mol', 'n_bonds_0', 'n_bonds_1',\n",
    "            'max_distance_mol' , 'mean_distance_mol', 'dist','1/r2',\n",
    "            'spin', 'n_hyb_3', 'hyb_coupled_atom', '1/hyb',\n",
    "            'volume', 'max diag', 'median diag', 'min diag',\n",
    "       'distance_atomic_weight_0', 'distance_en_allen_0',\n",
    "       'distance_atomic_weight_1', 'distance_en_allen_1', 'C_0d_0', 'N_0d_0',\n",
    "       'O_0d_0', 'C_1d_0', 'H_1d_0', 'N_1d_0', 'O_1d_0', 'C_2d_0', 'F_2d_0',\n",
    "       'H_2d_0', 'N_2d_0', 'O_2d_0', 'C_3d_0', 'F_3d_0', 'H_3d_0', 'N_3d_0',\n",
    "       'O_3d_0', 'C_4d_0', 'F_4d_0', 'H_4d_0', 'N_4d_0', 'O_4d_0', 'C_0d_1',\n",
    "       'F_0d_1', 'H_0d_1', 'N_0d_1', 'O_0d_1', 'C_1d_1', 'F_1d_1', 'H_1d_1',\n",
    "       'N_1d_1', 'O_1d_1', 'C_2d_1', 'F_2d_1', 'H_2d_1', 'N_2d_1', 'O_2d_1',\n",
    "       'C_3d_1', 'F_3d_1', 'H_3d_1', 'N_3d_1', 'O_3d_1', 'C_4d_1', 'F_4d_1',\n",
    "       'H_4d_1', 'N_4d_1', 'O_4d_1'],\n",
    "    '2JHN': ['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1', 'n_atoms', 'n_C', 'n_F',\n",
    "            'n_H', 'n_N', 'n_O', 'type_1__C', 'type_1__H', 'type_1__N', 'angles',\n",
    "            'n_bonds_mol', 'n_bonds_0', 'n_bonds_1',\n",
    "            'max_distance_mol' , 'mean_distance_mol', 'dist','1/r2',\n",
    "            'spin', 'n_hyb_3', 'hyb_coupled_atom', '1/hyb',\n",
    "            'volume', 'max diag', 'median diag', 'min diag',\n",
    "       'distance_atomic_weight_0', 'distance_en_allen_0',\n",
    "       'distance_atomic_weight_1', 'distance_en_allen_1', 'C_0d_0', 'N_0d_0',\n",
    "       'O_0d_0', 'C_1d_0', 'H_1d_0', 'N_1d_0', 'O_1d_0', 'C_2d_0', 'F_2d_0',\n",
    "       'H_2d_0', 'N_2d_0', 'O_2d_0', 'C_3d_0', 'F_3d_0', 'H_3d_0', 'N_3d_0',\n",
    "       'O_3d_0', 'C_4d_0', 'F_4d_0', 'H_4d_0', 'N_4d_0', 'O_4d_0', 'C_0d_1',\n",
    "       'F_0d_1', 'H_0d_1', 'N_0d_1', 'O_0d_1', 'C_1d_1', 'F_1d_1', 'H_1d_1',\n",
    "       'N_1d_1', 'O_1d_1', 'C_2d_1', 'F_2d_1', 'H_2d_1', 'N_2d_1', 'O_2d_1',\n",
    "       'C_3d_1', 'F_3d_1', 'H_3d_1', 'N_3d_1', 'O_3d_1', 'C_4d_1', 'F_4d_1',\n",
    "       'H_4d_1', 'N_4d_1', 'O_4d_1'],\n",
    "    '2JHC': ['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1', 'n_atoms', 'n_C', 'n_F',\n",
    "            'n_H', 'n_N', 'n_O', 'type_1__C', 'type_1__H', 'type_1__N', 'angles',\n",
    "            'n_bonds_mol', 'n_bonds_0', 'n_bonds_1',\n",
    "            'max_distance_mol' , 'mean_distance_mol', 'dist','1/r2',\n",
    "            'spin', 'n_hyb_3', 'hyb_coupled_atom', '1/hyb',\n",
    "            'volume', 'max diag', 'median diag', 'min diag',\n",
    "       'distance_atomic_weight_0', 'distance_en_allen_0',\n",
    "       'distance_atomic_weight_1', 'distance_en_allen_1', 'C_0d_0', 'N_0d_0',\n",
    "       'O_0d_0', 'C_1d_0', 'H_1d_0', 'N_1d_0', 'O_1d_0', 'C_2d_0', 'F_2d_0',\n",
    "       'H_2d_0', 'N_2d_0', 'O_2d_0', 'C_3d_0', 'F_3d_0', 'H_3d_0', 'N_3d_0',\n",
    "       'O_3d_0', 'C_4d_0', 'F_4d_0', 'H_4d_0', 'N_4d_0', 'O_4d_0', 'C_0d_1',\n",
    "       'F_0d_1', 'H_0d_1', 'N_0d_1', 'O_0d_1', 'C_1d_1', 'F_1d_1', 'H_1d_1',\n",
    "       'N_1d_1', 'O_1d_1', 'C_2d_1', 'F_2d_1', 'H_2d_1', 'N_2d_1', 'O_2d_1',\n",
    "       'C_3d_1', 'F_3d_1', 'H_3d_1', 'N_3d_1', 'O_3d_1', 'C_4d_1', 'F_4d_1',\n",
    "       'H_4d_1', 'N_4d_1', 'O_4d_1'],\n",
    "    '3JHH': ['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1', 'n_atoms', 'n_C', 'n_F',\n",
    "             'n_H', 'n_N', 'n_O', 'type_1__C', 'type_1__H', 'type_1__N',\n",
    "             'torsions', 'n_bonds_mol', 'n_bonds_0', 'n_bonds_1', 'karplus_1',\n",
    "             'karplus_2', 'max_distance_mol' , 'mean_distance_mol', 'dist','1/r2',\n",
    "            'spin', 'n_hyb_3', 'hyb_coupled_atom', '1/hyb',\n",
    "            'volume', 'max diag', 'median diag', 'min diag',\n",
    "       'distance_atomic_weight_0', 'distance_en_allen_0',\n",
    "       'distance_atomic_weight_1', 'distance_en_allen_1', 'C_0d_0', 'N_0d_0',\n",
    "       'O_0d_0', 'C_1d_0', 'H_1d_0', 'N_1d_0', 'O_1d_0', 'C_2d_0', 'F_2d_0',\n",
    "       'H_2d_0', 'N_2d_0', 'O_2d_0', 'C_3d_0', 'F_3d_0', 'H_3d_0', 'N_3d_0',\n",
    "       'O_3d_0', 'C_4d_0', 'F_4d_0', 'H_4d_0', 'N_4d_0', 'O_4d_0', 'C_0d_1',\n",
    "       'F_0d_1', 'H_0d_1', 'N_0d_1', 'O_0d_1', 'C_1d_1', 'F_1d_1', 'H_1d_1',\n",
    "       'N_1d_1', 'O_1d_1', 'C_2d_1', 'F_2d_1', 'H_2d_1', 'N_2d_1', 'O_2d_1',\n",
    "       'C_3d_1', 'F_3d_1', 'H_3d_1', 'N_3d_1', 'O_3d_1', 'C_4d_1', 'F_4d_1',\n",
    "       'H_4d_1', 'N_4d_1', 'O_4d_1'], \n",
    "    '3JHC': ['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1', 'n_atoms', 'n_C', 'n_F',\n",
    "             'n_H', 'n_N', 'n_O', 'type_1__C', 'type_1__H', 'type_1__N',\n",
    "             'torsions', 'n_bonds_mol', 'n_bonds_0', 'n_bonds_1', 'karplus_1',\n",
    "             'karplus_2', 'max_distance_mol' , 'mean_distance_mol', 'dist','1/r2',\n",
    "            'spin', 'n_hyb_3', 'hyb_coupled_atom', '1/hyb',\n",
    "            'volume', 'max diag', 'median diag', 'min diag',\n",
    "       'distance_atomic_weight_0', 'distance_en_allen_0',\n",
    "       'distance_atomic_weight_1', 'distance_en_allen_1', 'C_0d_0', 'N_0d_0',\n",
    "       'O_0d_0', 'C_1d_0', 'H_1d_0', 'N_1d_0', 'O_1d_0', 'C_2d_0', 'F_2d_0',\n",
    "       'H_2d_0', 'N_2d_0', 'O_2d_0', 'C_3d_0', 'F_3d_0', 'H_3d_0', 'N_3d_0',\n",
    "       'O_3d_0', 'C_4d_0', 'F_4d_0', 'H_4d_0', 'N_4d_0', 'O_4d_0', 'C_0d_1',\n",
    "       'F_0d_1', 'H_0d_1', 'N_0d_1', 'O_0d_1', 'C_1d_1', 'F_1d_1', 'H_1d_1',\n",
    "       'N_1d_1', 'O_1d_1', 'C_2d_1', 'F_2d_1', 'H_2d_1', 'N_2d_1', 'O_2d_1',\n",
    "       'C_3d_1', 'F_3d_1', 'H_3d_1', 'N_3d_1', 'O_3d_1', 'C_4d_1', 'F_4d_1',\n",
    "       'H_4d_1', 'N_4d_1', 'O_4d_1'], \n",
    "    '3JHN': ['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1', 'n_atoms', 'n_C', 'n_F',\n",
    "             'n_H', 'n_N', 'n_O', 'type_1__C', 'type_1__H', 'type_1__N',\n",
    "             'torsions', 'n_bonds_mol', 'n_bonds_0', 'n_bonds_1', 'karplus_1',\n",
    "             'karplus_2', 'max_distance_mol' , 'mean_distance_mol', 'dist','1/r2',\n",
    "            'spin', 'n_hyb_3', 'hyb_coupled_atom', '1/hyb',\n",
    "            'volume', 'max diag', 'median diag', 'min diag',\n",
    "       'distance_atomic_weight_0', 'distance_en_allen_0',\n",
    "       'distance_atomic_weight_1', 'distance_en_allen_1', 'C_0d_0', 'N_0d_0',\n",
    "       'O_0d_0', 'C_1d_0', 'H_1d_0', 'N_1d_0', 'O_1d_0', 'C_2d_0', 'F_2d_0',\n",
    "       'H_2d_0', 'N_2d_0', 'O_2d_0', 'C_3d_0', 'F_3d_0', 'H_3d_0', 'N_3d_0',\n",
    "       'O_3d_0', 'C_4d_0', 'F_4d_0', 'H_4d_0', 'N_4d_0', 'O_4d_0', 'C_0d_1',\n",
    "       'F_0d_1', 'H_0d_1', 'N_0d_1', 'O_0d_1', 'C_1d_1', 'F_1d_1', 'H_1d_1',\n",
    "       'N_1d_1', 'O_1d_1', 'C_2d_1', 'F_2d_1', 'H_2d_1', 'N_2d_1', 'O_2d_1',\n",
    "       'C_3d_1', 'F_3d_1', 'H_3d_1', 'N_3d_1', 'O_3d_1', 'C_4d_1', 'F_4d_1',\n",
    "       'H_4d_1', 'N_4d_1', 'O_4d_1']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Hyperparameters\n",
    "\n",
    "Create a dictionary for the hyperparameters found in a small hyperparameter tuning for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'1JHC': {'bootstrap': False,\n",
    "  'max_depth': None,\n",
    "  'max_features': 6,\n",
    "  'min_samples_split': 10},\n",
    " '2JHH': {'bootstrap': False,\n",
    "  'max_depth': None,\n",
    "  'max_features': 8,\n",
    "  'min_samples_split': 4},\n",
    " '1JHN': {'bootstrap': False,\n",
    "  'max_depth': None,\n",
    "  'max_features': 8,\n",
    "  'min_samples_split': 4},\n",
    " '2JHN': {'bootstrap': False,\n",
    "  'max_depth': None,\n",
    "  'max_features': 8,\n",
    "  'min_samples_split': 4},\n",
    " '2JHC': {'bootstrap': False,\n",
    "  'max_depth': None,\n",
    "  'max_features': 6,\n",
    "  'min_samples_split': 10},\n",
    " '3JHH': {'bootstrap': False,\n",
    "  'max_depth': None,\n",
    "  'max_features': 8,\n",
    "  'min_samples_split': 4},\n",
    " '3JHC': {'bootstrap': False,\n",
    "  'max_depth': None,\n",
    "  'max_features': 8,\n",
    "  'min_samples_split': 4},\n",
    " '3JHN': {'bootstrap': False,\n",
    "  'max_depth': None,\n",
    "  'max_features': 8,\n",
    "  'min_samples_split': 4}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 709416 samples for 1JHC ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50building tree 2 of 50\n",
      "\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! 1/8\n",
      "Train MAE: 0.5826051606954028 \n",
      "\n",
      "Fitting 378036 samples for 2JHH ...\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   54.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! 2/8\n",
      "Train MAE: 0.03335833935744555 \n",
      "\n",
      "Fitting 43363 samples for 1JHN ...\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    4.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! 3/8\n",
      "Train MAE: 0.06459851380593291 \n",
      "\n",
      "Fitting 119253 samples for 2JHN ...\n",
      "building tree 1 of 50building tree 2 of 50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   15.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   20.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! 4/8\n",
      "Train MAE: 0.02751250043314705 \n",
      "\n",
      "Fitting 1140674 samples for 2JHC ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! 5/8\n",
      "Train MAE: 0.21231746046953442 \n",
      "\n",
      "Fitting 590611 samples for 3JHH ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50building tree 2 of 50\n",
      "\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! 6/8\n",
      "Train MAE: 0.0277452898473549 \n",
      "\n",
      "Fitting 1510379 samples for 3JHC ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  5.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  7.0min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   31.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   18.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! 7/8\n",
      "Train MAE: 0.04746839828485104 \n",
      "\n",
      "Fitting 166415 samples for 3JHN ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   26.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   37.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! 8/8\n",
      "Train MAE: 0.018588197192906594 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.DataFrame()\n",
    "train_predictions = pd.DataFrame()\n",
    "keys = list(train_dfs_dict.keys())\n",
    "\n",
    "for i, key in enumerate(keys):\n",
    "    \n",
    "    train_df = train_dfs_dict[key]\n",
    "    test_df = test_dfs_dict[key]\n",
    "    y_train = targets_dict[key]\n",
    "    features = features_coupling_type[key]  \n",
    "    \n",
    "    train_pred_df = pd.DataFrame()\n",
    "    test_pred_df = pd.DataFrame()\n",
    "    train_pred_df['id'] = train_df['id']\n",
    "    test_pred_df['id'] = test_df['id']\n",
    "    \n",
    "    X_train = train_df[features]\n",
    "    X_test = test_df[features]\n",
    "    \n",
    "    print('Fitting {0} samples for {1} ...'.format(len(train_pred_df), key))\n",
    "    \n",
    "    tuned_params = best_params[key]\n",
    "    rf_reg = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=2, verbose=2, **tuned_params)\n",
    "    rf_reg.fit(X_train, y_train)\n",
    "    dump(rf_reg, './models_win/rf_reg_{}.joblib'.format(key))\n",
    "    y_hat_train = rf_reg.predict(X_train)\n",
    "    y_hat_test = rf_reg.predict(X_test)\n",
    "    \n",
    "    print('Finished training! {}/8'.format(i+1))\n",
    "    \n",
    "    train_pred_df['scalar_coupling_constant'] = y_hat_train\n",
    "    test_pred_df['scalar_coupling_constant'] = y_hat_test\n",
    "    train_predictions = train_predictions.append(train_pred_df)\n",
    "    submission_df = submission_df.append(test_pred_df)\n",
    "    \n",
    "    score = mean_absolute_error(y_train, y_hat_train)\n",
    "    \n",
    "    print('Train MAE:', score, '\\n')\n",
    "    \n",
    "    del test_dfs_dict[key], train_dfs_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = submission_df.sort_values('id')\n",
    "submission_df.to_csv('./submissions/neighbors_features.csv', index=False)\n",
    "train_predictions.to_csv('./data/predicted_couplings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:magnetic]",
   "language": "python",
   "name": "conda-env-magnetic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
